{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb17fbc-9fb8-47ae-a27d-3f598fa5b6f5",
   "metadata": {},
   "source": [
    "# Assumptions and Target\n",
    "\n",
    "Addressing the *degradation problem* observed in deep learning models through the introduction of the residual mapping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6c4c3-b152-4b02-8b3f-aee650c8ef3b",
   "metadata": {},
   "source": [
    "### Deep Residual Learning: starting point\n",
    "\n",
    "[From :Deep Residual Learning for Image Recognition - Introduction]\n",
    "\n",
    "Previous research demonstrated that network depth plays a crucial role in achieving improved results for image classification. For example, \"very deep\" convolutional networks have shown significant performance gains (see K. Simonyan and A. Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, ICLR, 2015).\n",
    "Deep neural networks include low-, mid-, and high-level features that can be enhanced by increasing the number of stacked layers (i.e., network depth).\n",
    "\n",
    "The depth of the network naturally leads to the following question:\n",
    "> \"_Is learning **better networks** as easy as **stacking more layers**?_\"\n",
    "\n",
    "Answering this question required addressing convergence challenges, which had to dealt with the well-known problem of vanishing/exploding gradients.\n",
    "\n",
    "Although this issue has been mitigated by techniques such as normalized initialization and intermediate normalization layers, another challenge emerges when deeper networks begin to converge:\n",
    "\n",
    "A **degradation problem** arises, where **increasing network depth** leads to **saturated accuracy** (an unsurprising phenomenon) and, more problematically, to a rapid **decline in accuracy**.\n",
    "\n",
    "Surprisingly, this degradation is not caused by overfitting. Adding more layers to an already suitably deep model results in higher training error.\n",
    "This degradation indicates that **not all systems are equally easy to optimize**.\n",
    "\n",
    "In their work, Deep Residual Learning for Image Recognition, the authors address this degradation problem by introducing a deep residual learning framework. This framework explicitly allows layers to fit a residual mapping, rather than assuming they can independently learn the desired mapping.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa15edc-ec18-4506-968f-64dab3397476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
